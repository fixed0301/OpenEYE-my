{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-28T03:19:53.208366400Z",
     "start_time": "2023-10-28T03:19:43.537500900Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 24):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    # torch.cuda.manual_seed(seed)\n",
    "    # torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-28T03:19:56.427640300Z",
     "start_time": "2023-10-28T03:19:56.380735100Z"
    }
   },
   "id": "f002b9611a9becaa"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "closed_path = '../dataset/realImg/eyes-only-22/closed'\n",
    "opened_path =  '../dataset/realImg/eyes-only-22/opened'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-28T03:19:57.953666600Z",
     "start_time": "2023-10-28T03:19:57.910352300Z"
    }
   },
   "id": "7d5c45bf0d389b8d"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_dataset_paths(data_dir): # '../dataset/realImg/eyes-only-22'\n",
    "    label_list = []\n",
    "\n",
    "    opened_dir = os.path.join(data_dir, \"opened\")\n",
    "    closed_dir = os.path.join(data_dir, \"closed\")\n",
    "\n",
    "    opened_img_paths = glob(os.path.join(opened_dir, '*.jpg'))\n",
    "    opened_img_paths.sort(key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "\n",
    "    closed_img_paths = glob(os.path.join(closed_dir, '*.jpg'))\n",
    "    closed_img_paths.sort(key=lambda x: int(x.split('_')[-1].split('.')[0]))\n",
    "\n",
    "    # \"opened\" 레이블은 1,  \"closed\" 레이블은 0으로 지정\n",
    "    label_list.extend([1] * len(opened_img_paths))\n",
    "    label_list.extend([0] * len(closed_img_paths))\n",
    "    img_path_list = opened_img_paths + closed_img_paths\n",
    "    return img_path_list, label_list\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-28T03:19:59.166953200Z",
     "start_time": "2023-10-28T03:19:59.135698700Z"
    }
   },
   "id": "f3ecf51d93544359"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "def shuffle_dataset(img_path_list, label_list):\n",
    "    img_path_list, label_list = shuffle(img_path_list, label_list, random_state=42)\n",
    "    return img_path_list, label_list"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-28T03:20:07.114242300Z",
     "start_time": "2023-10-28T03:20:00.443317600Z"
    }
   },
   "id": "805868e38fcb2440"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "img_path_list, label_list = get_dataset_paths('../dataset/realImg/eyes-only-22')\n",
    "all_img_path, all_label = shuffle_dataset(img_path_list, label_list)\n",
    "print(all_label)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-28T03:20:08.411274700Z",
     "start_time": "2023-10-28T03:20:08.260043700Z"
    }
   },
   "id": "54896fe7eeeaa5f7"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_path_list, label_list, train_mode=True, transforms=None):\n",
    "        self.transforms = transforms\n",
    "        self.train_mode = train_mode\n",
    "        self.img_path_list = img_path_list\n",
    "        self.label_list = label_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)\n",
    "\n",
    "    def __getitem__(self, index):  \n",
    "        img_path = self.img_path_list[index]\n",
    "        image = cv2.imread(img_path)\n",
    "    \n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "            \n",
    "        if self.train_mode:\n",
    "            label = self.label_list[index]\n",
    "            return image, label\n",
    "    \n",
    "        else:\n",
    "            return image"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-28T03:20:11.043320Z",
     "start_time": "2023-10-28T03:20:11.027537200Z"
    }
   },
   "id": "ce536debd5d0d6eb"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# train : test: val = 0.8 : 0.1 : 0.1\n",
    "\n",
    "train_len = int(len(all_img_path)*0.8)\n",
    "test_len = int(len(all_img_path)*0.1)\n",
    "val_len = int(len(all_img_path)*0.1)\n",
    "              \n",
    "train_img_path = all_img_path[:train_len]\n",
    "train_label = all_label[:train_len]\n",
    "\n",
    "test_img_path = all_img_path[train_len: train_len + test_len]\n",
    "test_label = all_img_path[train_len: train_len + test_len]\n",
    "\n",
    "val_img_path = all_img_path[train_len + test_len:]\n",
    "val_label = all_label[train_len + test_len:]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-28T03:20:13.026170700Z",
     "start_time": "2023-10-28T03:20:12.978711900Z"
    }
   },
   "id": "e15dfa09497c9288"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, test, val length: 4463 557 557\n"
     ]
    }
   ],
   "source": [
    "print('train, test, val length:', train_len, test_len, val_len)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-28T03:20:14.368069400Z",
     "start_time": "2023-10-28T03:20:14.351252600Z"
    }
   },
   "id": "aee102bd01ccd59a"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 \n",
    "CFG = {\n",
    "    'IMG_SIZE':128,\n",
    "    'EPOCHS':10, \n",
    "    'LEARNING_RATE':2e-2, \n",
    "    'BATCH_SIZE':12, \n",
    "    'SEED':24, \n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-28T10:38:21.448085300Z",
     "start_time": "2023-10-28T10:38:21.397832100Z"
    }
   },
   "id": "f10a15cb39ff0de5"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(), \n",
    "    transforms.Resize([CFG['IMG_SIZE'], CFG['IMG_SIZE']]), \n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)) \n",
    "\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize([CFG['IMG_SIZE'], CFG['IMG_SIZE']]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-28T03:20:16.831943Z",
     "start_time": "2023-10-28T03:20:16.815868500Z"
    }
   },
   "id": "bf39b19027dba551"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# train_batches = len(train_loader)\n",
    "# test_batches = len(test_loader)\n",
    "# \n",
    "# print('total train imgs :', train_len,'/ total train batches :', train_batches)\n",
    "# print('total test imgs :', val_len, '/ total test batches :', test_batches)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-28T03:20:19.818870Z",
     "start_time": "2023-10-28T03:20:19.791728600Z"
    }
   },
   "id": "8eeac89408335a0e"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# 사진 확인하기\n",
    "# train_features, train_labels = next(iter(train_loader))  \n",
    "# img = train_features[0]\n",
    "# label = train_labels[0]\n",
    "# plt.imshow(img[0], cmap=\"gray\")\n",
    "# plt.show()\n",
    "# print(f\"Label: {label}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-28T03:20:20.593456600Z",
     "start_time": "2023-10-28T03:20:20.561851100Z"
    }
   },
   "id": "c10385d2801c73e7"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.model = torchvision.models.resnet18(pretrained = False)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.classifier = nn.Linear(1000, 10)\n",
    "\n",
    "    def forward(self, images):\n",
    "        outputs = self.model(images)\n",
    "        outputs = self.dropout(outputs)\n",
    "        outputs = self.classifier(outputs)\n",
    "        return outputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-28T03:20:21.667650900Z",
     "start_time": "2023-10-28T03:20:21.636263100Z"
    }
   },
   "id": "5243037395cb6e72"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# k-fold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 4)\n",
    "folds=[]\n",
    "for trn_idx,val_idx in skf.split(train_img_path, train_label):\n",
    "    folds.append((trn_idx,val_idx))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-28T15:50:37.599868800Z",
     "start_time": "2023-10-28T15:50:37.553482700Z"
    }
   },
   "id": "4f68423b2a02d61a"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============== 1 fold start===============\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 - Loss: 191.763306\n",
      "Epoch: 0 - Loss: 6.679359\n",
      "Epoch: 0 - Loss: 0.653717\n",
      "Epoch: 0 - Loss: 2.368544\n",
      "Epoch: 0 - Loss: 0.340592\n",
      "Epoch: 0 - Loss: 0.190015\n",
      "Epoch: 0 - Loss: 0.346462\n",
      "Epoch: 0 - Loss: 0.861421\n",
      "Epoch: 0 - Loss: 0.312239\n",
      "Epoch: 0 - Loss: 0.341255\n",
      "Epoch: 0 - Loss: 0.389755\n",
      "Epoch: 0 - Loss: 0.292173\n",
      "Epoch: 0 - Loss: 0.385165\n",
      "Epoch: 0 - Loss: 0.242726\n",
      "Epoch: 0 - Loss: 0.182806\n",
      "Epoch: 0 - Loss: 0.197053\n",
      "Epoch: 0 - Loss: 0.184065\n",
      "Epoch: 0 - Loss: 0.936939\n",
      "Epoch: 0 - valid Loss: 0.369604 - valid_acc : 0.856890\n",
      "Epoch: 1 - Loss: 0.319737\n",
      "Epoch: 1 - Loss: 0.117405\n",
      "Epoch: 1 - Loss: 0.160632\n",
      "Epoch: 1 - Loss: 0.070710\n",
      "Epoch: 1 - Loss: 0.545494\n",
      "Epoch: 1 - Loss: 0.173050\n",
      "Epoch: 1 - Loss: 0.123139\n",
      "Epoch: 1 - Loss: 0.210491\n",
      "Epoch: 1 - Loss: 0.086899\n",
      "Epoch: 1 - Loss: 0.051603\n",
      "Epoch: 1 - Loss: 0.899853\n",
      "Epoch: 1 - Loss: 0.136711\n",
      "Epoch: 1 - Loss: 0.159089\n",
      "Epoch: 1 - Loss: 0.051506\n",
      "Epoch: 1 - Loss: 0.019256\n",
      "Epoch: 1 - Loss: 0.031649\n",
      "Epoch: 1 - Loss: 0.704862\n",
      "Epoch: 1 - Loss: 0.208332\n",
      "Epoch: 1 - valid Loss: 0.232544 - valid_acc : 0.933131\n",
      "Epoch: 2 - Loss: 0.020717\n",
      "Epoch: 2 - Loss: 0.126174\n",
      "Epoch: 2 - Loss: 0.297126\n",
      "Epoch: 2 - Loss: 0.311670\n",
      "Epoch: 2 - Loss: 0.466066\n",
      "Epoch: 2 - Loss: 0.053816\n",
      "Epoch: 2 - Loss: 0.030437\n",
      "Epoch: 2 - Loss: 0.071993\n",
      "Epoch: 2 - Loss: 0.104223\n",
      "Epoch: 2 - Loss: 0.243616\n",
      "Epoch: 2 - Loss: 0.128141\n",
      "Epoch: 2 - Loss: 0.061597\n",
      "Epoch: 2 - Loss: 0.250553\n",
      "Epoch: 2 - Loss: 0.485601\n",
      "Epoch: 2 - Loss: 0.276099\n",
      "Epoch: 2 - Loss: 0.094074\n",
      "Epoch: 2 - Loss: 0.062195\n",
      "Epoch: 2 - Loss: 0.030691\n",
      "Epoch: 2 - valid Loss: 0.179420 - valid_acc : 0.943769\n",
      "Epoch: 3 - Loss: 0.380659\n",
      "Epoch: 3 - Loss: 0.053835\n",
      "Epoch: 3 - Loss: 0.038480\n",
      "Epoch: 3 - Loss: 1.250805\n",
      "Epoch: 3 - Loss: 0.067158\n",
      "Epoch: 3 - Loss: 0.296397\n",
      "Epoch: 3 - Loss: 0.264902\n",
      "Epoch: 3 - Loss: 0.161506\n",
      "Epoch: 3 - Loss: 0.140002\n",
      "Epoch: 3 - Loss: 0.134341\n",
      "Epoch: 3 - Loss: 0.325813\n",
      "Epoch: 3 - Loss: 0.045785\n",
      "Epoch: 3 - Loss: 0.116343\n",
      "Epoch: 3 - Loss: 0.069339\n",
      "Epoch: 3 - Loss: 0.062707\n",
      "Epoch: 3 - Loss: 0.000010\n",
      "Epoch: 3 - Loss: 0.013879\n",
      "Epoch: 3 - Loss: 0.056639\n",
      "Epoch: 3 - valid Loss: 0.300812 - valid_acc : 0.926039\n",
      "Epoch: 4 - Loss: 0.135451\n",
      "Epoch: 4 - Loss: 0.256334\n",
      "Epoch: 4 - Loss: 0.013152\n",
      "Epoch: 4 - Loss: 0.258995\n",
      "Epoch: 4 - Loss: 0.379118\n",
      "Epoch: 4 - Loss: 0.016819\n",
      "Epoch: 4 - Loss: 0.684130\n",
      "Epoch: 4 - Loss: 0.009722\n",
      "Epoch: 4 - Loss: 0.031117\n",
      "Epoch: 4 - Loss: 0.053276\n",
      "Epoch: 4 - Loss: 0.009500\n",
      "Epoch: 4 - Loss: 0.032223\n",
      "Epoch: 4 - Loss: 0.147425\n",
      "Epoch: 4 - Loss: 0.018111\n",
      "Epoch: 4 - Loss: 0.009236\n",
      "Epoch: 4 - Loss: 0.051659\n",
      "Epoch: 4 - Loss: 0.022661\n",
      "Epoch: 4 - Loss: 0.164501\n",
      "Epoch: 4 - valid Loss: 0.178623 - valid_acc : 0.936677\n",
      "Epoch: 5 - Loss: 0.020153\n",
      "Epoch: 5 - Loss: 0.014718\n",
      "Epoch: 5 - Loss: 0.063697\n",
      "Epoch: 5 - Loss: 0.018839\n",
      "Epoch: 5 - Loss: 0.030236\n",
      "Epoch: 5 - Loss: 0.069035\n",
      "Epoch: 5 - Loss: 0.224861\n",
      "Epoch: 5 - Loss: 0.026372\n",
      "Epoch: 5 - Loss: 0.032511\n",
      "Epoch: 5 - Loss: 0.013462\n",
      "Epoch: 5 - Loss: 0.105990\n",
      "Epoch: 5 - Loss: 0.007468\n",
      "Epoch: 5 - Loss: 0.565685\n",
      "Epoch: 5 - Loss: 0.014985\n",
      "Epoch: 5 - Loss: 0.057034\n",
      "Epoch: 5 - Loss: 0.022594\n",
      "Epoch: 5 - Loss: 0.015517\n",
      "Epoch: 5 - Loss: 0.044520\n",
      "Epoch: 5 - valid Loss: 0.186108 - valid_acc : 0.917680\n",
      "Epoch: 6 - Loss: 0.002186\n",
      "Epoch: 6 - Loss: 1.183117\n",
      "Epoch: 6 - Loss: 0.029013\n",
      "Epoch: 6 - Loss: 0.129038\n",
      "Epoch: 6 - Loss: 0.013475\n",
      "Epoch: 6 - Loss: 0.029577\n",
      "Epoch: 6 - Loss: 0.033968\n",
      "Epoch: 6 - Loss: 0.085224\n",
      "Epoch: 6 - Loss: 0.059516\n",
      "Epoch: 6 - Loss: 0.125233\n",
      "Epoch: 6 - Loss: 0.024724\n",
      "Epoch: 6 - Loss: 0.118687\n",
      "Epoch: 6 - Loss: 0.032928\n",
      "Epoch: 6 - Loss: 0.005564\n",
      "Epoch: 6 - Loss: 0.403529\n",
      "Epoch: 6 - Loss: 0.161765\n",
      "Epoch: 6 - Loss: 0.062215\n",
      "Epoch: 6 - Loss: 0.192955\n",
      "Epoch: 6 - valid Loss: 0.153119 - valid_acc : 0.961499\n",
      "Epoch: 7 - Loss: 0.076232\n",
      "Epoch: 7 - Loss: 0.718951\n",
      "Epoch: 7 - Loss: 0.025518\n",
      "Epoch: 7 - Loss: 0.112611\n",
      "Epoch: 7 - Loss: 0.278190\n",
      "Epoch: 7 - Loss: 0.580081\n",
      "Epoch: 7 - Loss: 0.518639\n",
      "Epoch: 7 - Loss: 0.692571\n",
      "Epoch: 7 - Loss: 0.017526\n",
      "Epoch: 7 - Loss: 0.192385\n",
      "Epoch: 7 - Loss: 0.006904\n",
      "Epoch: 7 - Loss: 0.182296\n",
      "Epoch: 7 - Loss: 0.009675\n",
      "Epoch: 7 - Loss: 0.011839\n",
      "Epoch: 7 - Loss: 0.275468\n",
      "Epoch: 7 - Loss: 0.542000\n",
      "Epoch: 7 - Loss: 0.049724\n",
      "Epoch: 7 - Loss: 0.039173\n",
      "Epoch: 7 - valid Loss: 0.136926 - valid_acc : 0.968592\n",
      "Epoch: 8 - Loss: 0.219936\n",
      "Epoch: 8 - Loss: 0.014770\n",
      "Epoch: 8 - Loss: 0.053641\n",
      "Epoch: 8 - Loss: 0.011341\n",
      "Epoch: 8 - Loss: 0.042667\n",
      "Epoch: 8 - Loss: 0.007893\n",
      "Epoch: 8 - Loss: 0.003808\n",
      "Epoch: 8 - Loss: 0.013546\n",
      "Epoch: 8 - Loss: 0.047392\n",
      "Epoch: 8 - Loss: 0.038491\n",
      "Epoch: 8 - Loss: 0.102046\n",
      "Epoch: 8 - Loss: 0.023995\n",
      "Epoch: 8 - Loss: 0.074162\n",
      "Epoch: 8 - Loss: 0.076491\n",
      "Epoch: 8 - Loss: 0.011019\n",
      "Epoch: 8 - Loss: 0.007220\n",
      "Epoch: 8 - Loss: 0.047397\n",
      "Epoch: 8 - Loss: 0.121443\n",
      "Epoch: 8 - valid Loss: 0.108979 - valid_acc : 0.972138\n",
      "Epoch: 9 - Loss: 0.053521\n",
      "Epoch: 9 - Loss: 0.003651\n",
      "Epoch: 9 - Loss: 0.003826\n",
      "Epoch: 9 - Loss: 0.078278\n",
      "Epoch: 9 - Loss: 0.007403\n",
      "Epoch: 9 - Loss: 0.006424\n",
      "Epoch: 9 - Loss: 0.012712\n",
      "Epoch: 9 - Loss: 0.012732\n",
      "Epoch: 9 - Loss: 0.001130\n",
      "Epoch: 9 - Loss: 0.006144\n",
      "Epoch: 9 - Loss: 0.203489\n",
      "Epoch: 9 - Loss: 0.031273\n",
      "Epoch: 9 - Loss: 0.014010\n",
      "Epoch: 9 - Loss: 0.033433\n",
      "Epoch: 9 - Loss: 0.018033\n",
      "Epoch: 9 - Loss: 0.000588\n",
      "Epoch: 9 - Loss: 0.146584\n",
      "Epoch: 9 - Loss: 0.137592\n",
      "Epoch: 9 - valid Loss: 0.110677 - valid_acc : 0.961500\n",
      "=============== 2 fold start===============\n",
      "Epoch: 0 - Loss: 0.648040\n",
      "Epoch: 0 - Loss: 1.155057\n",
      "Epoch: 0 - Loss: 0.220857\n",
      "Epoch: 0 - Loss: 0.334780\n",
      "Epoch: 0 - Loss: 0.519061\n",
      "Epoch: 0 - Loss: 1.103459\n",
      "Epoch: 0 - Loss: 0.600866\n",
      "Epoch: 0 - Loss: 0.587342\n",
      "Epoch: 0 - Loss: 0.780427\n",
      "Epoch: 0 - Loss: 0.145097\n",
      "Epoch: 0 - Loss: 0.813564\n",
      "Epoch: 0 - Loss: 1.268322\n",
      "Epoch: 0 - Loss: 0.185641\n",
      "Epoch: 0 - Loss: 0.226855\n",
      "Epoch: 0 - Loss: 0.531166\n",
      "Epoch: 0 - Loss: 0.672179\n",
      "Epoch: 0 - Loss: 0.052267\n",
      "Epoch: 0 - Loss: 0.295016\n",
      "Epoch: 0 - valid Loss: 0.532373 - valid_acc : 0.790527\n",
      "Epoch: 1 - Loss: 0.866372\n",
      "Epoch: 1 - Loss: 0.503928\n",
      "Epoch: 1 - Loss: 0.302191\n",
      "Epoch: 1 - Loss: 0.152830\n",
      "Epoch: 1 - Loss: 0.138733\n",
      "Epoch: 1 - Loss: 0.058627\n",
      "Epoch: 1 - Loss: 0.149468\n",
      "Epoch: 1 - Loss: 0.064971\n",
      "Epoch: 1 - Loss: 0.520845\n",
      "Epoch: 1 - Loss: 0.077768\n",
      "Epoch: 1 - Loss: 0.247999\n",
      "Epoch: 1 - Loss: 0.207400\n",
      "Epoch: 1 - Loss: 0.123883\n",
      "Epoch: 1 - Loss: 0.077111\n",
      "Epoch: 1 - Loss: 0.304628\n",
      "Epoch: 1 - Loss: 0.445361\n",
      "Epoch: 1 - Loss: 0.048216\n",
      "Epoch: 1 - Loss: 0.012178\n",
      "Epoch: 1 - valid Loss: 0.233764 - valid_acc : 0.924266\n",
      "Epoch: 2 - Loss: 0.030370\n",
      "Epoch: 2 - Loss: 0.049894\n",
      "Epoch: 2 - Loss: 0.126219\n",
      "Epoch: 2 - Loss: 0.021430\n",
      "Epoch: 2 - Loss: 0.084727\n",
      "Epoch: 2 - Loss: 0.064694\n",
      "Epoch: 2 - Loss: 0.544479\n",
      "Epoch: 2 - Loss: 0.132435\n",
      "Epoch: 2 - Loss: 0.104382\n",
      "Epoch: 2 - Loss: 0.065866\n",
      "Epoch: 2 - Loss: 0.087528\n",
      "Epoch: 2 - Loss: 0.018375\n",
      "Epoch: 2 - Loss: 0.035009\n",
      "Epoch: 2 - Loss: 0.750715\n",
      "Epoch: 2 - Loss: 0.117421\n",
      "Epoch: 2 - Loss: 0.302171\n",
      "Epoch: 2 - Loss: 0.154917\n",
      "Epoch: 2 - Loss: 0.407675\n",
      "Epoch: 2 - valid Loss: 0.165798 - valid_acc : 0.947315\n",
      "Epoch: 3 - Loss: 0.212416\n",
      "Epoch: 3 - Loss: 0.043776\n",
      "Epoch: 3 - Loss: 0.064985\n",
      "Epoch: 3 - Loss: 0.819376\n",
      "Epoch: 3 - Loss: 0.005610\n",
      "Epoch: 3 - Loss: 0.006023\n",
      "Epoch: 3 - Loss: 0.109530\n",
      "Epoch: 3 - Loss: 0.016984\n",
      "Epoch: 3 - Loss: 0.227296\n",
      "Epoch: 3 - Loss: 0.018614\n",
      "Epoch: 3 - Loss: 0.530189\n",
      "Epoch: 3 - Loss: 0.055031\n",
      "Epoch: 3 - Loss: 0.441308\n",
      "Epoch: 3 - Loss: 0.071296\n",
      "Epoch: 3 - Loss: 0.031649\n",
      "Epoch: 3 - Loss: 0.071283\n",
      "Epoch: 3 - Loss: 0.034232\n",
      "Epoch: 3 - Loss: 0.077512\n",
      "Epoch: 3 - valid Loss: 0.190987 - valid_acc : 0.949088\n",
      "Epoch: 4 - Loss: 0.012905\n",
      "Epoch: 4 - Loss: 0.049700\n",
      "Epoch: 4 - Loss: 0.066077\n",
      "Epoch: 4 - Loss: 0.052300\n",
      "Epoch: 4 - Loss: 0.258156\n",
      "Epoch: 4 - Loss: 0.202216\n",
      "Epoch: 4 - Loss: 0.028982\n",
      "Epoch: 4 - Loss: 0.033672\n",
      "Epoch: 4 - Loss: 0.036815\n",
      "Epoch: 4 - Loss: 0.006317\n",
      "Epoch: 4 - Loss: 0.039377\n",
      "Epoch: 4 - Loss: 0.016413\n",
      "Epoch: 4 - Loss: 0.229108\n",
      "Epoch: 4 - Loss: 0.138277\n",
      "Epoch: 4 - Loss: 0.133107\n",
      "Epoch: 4 - Loss: 0.043713\n",
      "Epoch: 4 - Loss: 0.130574\n",
      "Epoch: 4 - Loss: 0.091198\n",
      "Epoch: 4 - valid Loss: 0.133626 - valid_acc : 0.952634\n",
      "Epoch: 5 - Loss: 0.008978\n",
      "Epoch: 5 - Loss: 0.011166\n",
      "Epoch: 5 - Loss: 0.082245\n",
      "Epoch: 5 - Loss: 0.080921\n",
      "Epoch: 5 - Loss: 0.053968\n",
      "Epoch: 5 - Loss: 0.006576\n",
      "Epoch: 5 - Loss: 0.515651\n",
      "Epoch: 5 - Loss: 0.073782\n",
      "Epoch: 5 - Loss: 0.018856\n",
      "Epoch: 5 - Loss: 0.249765\n",
      "Epoch: 5 - Loss: 0.059738\n",
      "Epoch: 5 - Loss: 0.265879\n",
      "Epoch: 5 - Loss: 0.138355\n",
      "Epoch: 5 - Loss: 0.018539\n",
      "Epoch: 5 - Loss: 0.109920\n",
      "Epoch: 5 - Loss: 0.002304\n",
      "Epoch: 5 - Loss: 0.046935\n",
      "Epoch: 5 - Loss: 0.945837\n",
      "Epoch: 5 - valid Loss: 0.178928 - valid_acc : 0.954407\n",
      "Epoch: 6 - Loss: 0.203491\n",
      "Epoch: 6 - Loss: 0.006882\n",
      "Epoch: 6 - Loss: 0.083285\n",
      "Epoch: 6 - Loss: 0.019363\n",
      "Epoch: 6 - Loss: 0.008026\n",
      "Epoch: 6 - Loss: 0.211742\n",
      "Epoch: 6 - Loss: 0.033061\n",
      "Epoch: 6 - Loss: 0.207422\n",
      "Epoch: 6 - Loss: 0.232403\n",
      "Epoch: 6 - Loss: 0.004938\n",
      "Epoch: 6 - Loss: 0.267675\n",
      "Epoch: 6 - Loss: 0.056840\n",
      "Epoch: 6 - Loss: 0.021134\n",
      "Epoch: 6 - Loss: 0.018527\n",
      "Epoch: 6 - Loss: 0.057868\n",
      "Epoch: 6 - Loss: 0.121127\n",
      "Epoch: 6 - Loss: 0.001275\n",
      "Epoch: 6 - Loss: 0.034557\n",
      "Epoch: 6 - valid Loss: 0.107714 - valid_acc : 0.977457\n",
      "Epoch: 7 - Loss: 0.010055\n",
      "Epoch: 7 - Loss: 0.005892\n",
      "Epoch: 7 - Loss: 0.031878\n",
      "Epoch: 7 - Loss: 0.009426\n",
      "Epoch: 7 - Loss: 0.548005\n",
      "Epoch: 7 - Loss: 0.010583\n",
      "Epoch: 7 - Loss: 0.028878\n",
      "Epoch: 7 - Loss: 0.014029\n",
      "Epoch: 7 - Loss: 0.089789\n",
      "Epoch: 7 - Loss: 0.004702\n",
      "Epoch: 7 - Loss: 0.012068\n",
      "Epoch: 7 - Loss: 0.003798\n",
      "Epoch: 7 - Loss: 0.023211\n",
      "Epoch: 7 - Loss: 0.039475\n",
      "Epoch: 7 - Loss: 0.024805\n",
      "Epoch: 7 - Loss: 0.369092\n",
      "Epoch: 7 - Loss: 0.003039\n",
      "Epoch: 7 - Loss: 0.016882\n",
      "Epoch: 7 - valid Loss: 0.104507 - valid_acc : 0.953901\n",
      "Epoch: 8 - Loss: 0.008212\n",
      "Epoch: 8 - Loss: 0.115821\n",
      "Epoch: 8 - Loss: 0.001575\n",
      "Epoch: 8 - Loss: 0.021140\n",
      "Epoch: 8 - Loss: 0.009605\n",
      "Epoch: 8 - Loss: 0.008513\n",
      "Epoch: 8 - Loss: 0.003934\n",
      "Epoch: 8 - Loss: 0.000687\n",
      "Epoch: 8 - Loss: 0.038846\n",
      "Epoch: 8 - Loss: 0.004018\n",
      "Epoch: 8 - Loss: 0.014481\n",
      "Epoch: 8 - Loss: 0.112272\n",
      "Epoch: 8 - Loss: 0.010974\n",
      "Epoch: 8 - Loss: 0.026737\n",
      "Epoch: 8 - Loss: 0.098094\n",
      "Epoch: 8 - Loss: 0.069544\n",
      "Epoch: 8 - Loss: 0.170596\n",
      "Epoch: 8 - Loss: 0.076884\n",
      "Epoch: 8 - valid Loss: 0.141725 - valid_acc : 0.950861\n",
      "Epoch: 9 - Loss: 0.281257\n",
      "Epoch: 9 - Loss: 0.007557\n",
      "Epoch: 9 - Loss: 0.020761\n",
      "Epoch: 9 - Loss: 0.084789\n",
      "Epoch: 9 - Loss: 0.031802\n",
      "Epoch: 9 - Loss: 0.050795\n",
      "Epoch: 9 - Loss: 0.000446\n",
      "Epoch: 9 - Loss: 0.023006\n",
      "Epoch: 9 - Loss: 0.003546\n",
      "Epoch: 9 - Loss: 0.115906\n",
      "Epoch: 9 - Loss: 0.011705\n",
      "Epoch: 9 - Loss: 0.023787\n",
      "Epoch: 9 - Loss: 0.225256\n",
      "Epoch: 9 - Loss: 0.035922\n",
      "Epoch: 9 - Loss: 0.005960\n",
      "Epoch: 9 - Loss: 0.413812\n",
      "Epoch: 9 - Loss: 0.105671\n",
      "Epoch: 9 - Loss: 0.005799\n",
      "Epoch: 9 - valid Loss: 0.157754 - valid_acc : 0.963273\n",
      "=============== 3 fold start===============\n",
      "Epoch: 0 - Loss: 5.472521\n",
      "Epoch: 0 - Loss: 0.044824\n",
      "Epoch: 0 - Loss: 0.701106\n",
      "Epoch: 0 - Loss: 0.650852\n",
      "Epoch: 0 - Loss: 0.192175\n",
      "Epoch: 0 - Loss: 0.464545\n",
      "Epoch: 0 - Loss: 0.275130\n",
      "Epoch: 0 - Loss: 0.666799\n",
      "Epoch: 0 - Loss: 0.499064\n",
      "Epoch: 0 - Loss: 0.708487\n",
      "Epoch: 0 - Loss: 0.798331\n",
      "Epoch: 0 - Loss: 0.268424\n",
      "Epoch: 0 - Loss: 0.707698\n",
      "Epoch: 0 - Loss: 0.289797\n",
      "Epoch: 0 - Loss: 0.313343\n",
      "Epoch: 0 - Loss: 0.263862\n",
      "Epoch: 0 - Loss: 0.426648\n",
      "Epoch: 0 - Loss: 0.218417\n",
      "Epoch: 0 - valid Loss: 0.194654 - valid_acc : 0.934904\n",
      "Epoch: 1 - Loss: 0.544343\n",
      "Epoch: 1 - Loss: 0.098345\n",
      "Epoch: 1 - Loss: 0.801523\n",
      "Epoch: 1 - Loss: 0.510968\n",
      "Epoch: 1 - Loss: 0.012127\n",
      "Epoch: 1 - Loss: 0.320386\n",
      "Epoch: 1 - Loss: 0.020171\n",
      "Epoch: 1 - Loss: 0.243918\n",
      "Epoch: 1 - Loss: 0.042126\n",
      "Epoch: 1 - Loss: 0.534184\n",
      "Epoch: 1 - Loss: 0.026868\n",
      "Epoch: 1 - Loss: 0.204537\n",
      "Epoch: 1 - Loss: 0.006528\n",
      "Epoch: 1 - Loss: 0.040674\n",
      "Epoch: 1 - Loss: 0.314604\n",
      "Epoch: 1 - Loss: 0.144214\n",
      "Epoch: 1 - Loss: 0.991229\n",
      "Epoch: 1 - Loss: 0.348985\n",
      "Epoch: 1 - valid Loss: 0.143693 - valid_acc : 0.950861\n",
      "Epoch: 2 - Loss: 0.051642\n",
      "Epoch: 2 - Loss: 0.723102\n",
      "Epoch: 2 - Loss: 0.118115\n",
      "Epoch: 2 - Loss: 0.007336\n",
      "Epoch: 2 - Loss: 0.815821\n",
      "Epoch: 2 - Loss: 0.039421\n",
      "Epoch: 2 - Loss: 0.170963\n",
      "Epoch: 2 - Loss: 0.004266\n",
      "Epoch: 2 - Loss: 0.283335\n",
      "Epoch: 2 - Loss: 0.040832\n",
      "Epoch: 2 - Loss: 0.004853\n",
      "Epoch: 2 - Loss: 0.010752\n",
      "Epoch: 2 - Loss: 0.917526\n",
      "Epoch: 2 - Loss: 0.005018\n",
      "Epoch: 2 - Loss: 0.510276\n",
      "Epoch: 2 - Loss: 0.087021\n",
      "Epoch: 2 - Loss: 0.068639\n",
      "Epoch: 2 - Loss: 0.001063\n",
      "Epoch: 2 - valid Loss: 0.132956 - valid_acc : 0.961500\n",
      "Epoch: 3 - Loss: 0.467783\n",
      "Epoch: 3 - Loss: 0.018440\n",
      "Epoch: 3 - Loss: 0.060135\n",
      "Epoch: 3 - Loss: 0.006146\n",
      "Epoch: 3 - Loss: 0.017832\n",
      "Epoch: 3 - Loss: 0.047873\n",
      "Epoch: 3 - Loss: 0.058569\n",
      "Epoch: 3 - Loss: 0.174790\n",
      "Epoch: 3 - Loss: 0.192251\n",
      "Epoch: 3 - Loss: 0.031404\n",
      "Epoch: 3 - Loss: 0.000421\n",
      "Epoch: 3 - Loss: 0.096494\n",
      "Epoch: 3 - Loss: 0.085182\n",
      "Epoch: 3 - Loss: 0.271823\n",
      "Epoch: 3 - Loss: 0.013698\n",
      "Epoch: 3 - Loss: 0.002908\n",
      "Epoch: 3 - Loss: 0.017048\n",
      "Epoch: 3 - Loss: 0.078704\n",
      "Epoch: 3 - valid Loss: 0.103902 - valid_acc : 0.965046\n",
      "Epoch: 4 - Loss: 0.024572\n",
      "Epoch: 4 - Loss: 0.206070\n",
      "Epoch: 4 - Loss: 0.249759\n",
      "Epoch: 4 - Loss: 0.026164\n",
      "Epoch: 4 - Loss: 0.061185\n",
      "Epoch: 4 - Loss: 0.058804\n",
      "Epoch: 4 - Loss: 0.126306\n",
      "Epoch: 4 - Loss: 0.135382\n",
      "Epoch: 4 - Loss: 0.385807\n",
      "Epoch: 4 - Loss: 0.048860\n",
      "Epoch: 4 - Loss: 0.044885\n",
      "Epoch: 4 - Loss: 0.107915\n",
      "Epoch: 4 - Loss: 0.001573\n",
      "Epoch: 4 - Loss: 0.039595\n",
      "Epoch: 4 - Loss: 0.105403\n",
      "Epoch: 4 - Loss: 0.206227\n",
      "Epoch: 4 - Loss: 0.085683\n",
      "Epoch: 4 - Loss: 0.060827\n",
      "Epoch: 4 - valid Loss: 0.120151 - valid_acc : 0.954407\n",
      "Epoch: 5 - Loss: 0.077752\n",
      "Epoch: 5 - Loss: 0.003950\n",
      "Epoch: 5 - Loss: 0.018065\n",
      "Epoch: 5 - Loss: 0.078454\n",
      "Epoch: 5 - Loss: 0.005893\n",
      "Epoch: 5 - Loss: 0.129076\n",
      "Epoch: 5 - Loss: 0.005079\n",
      "Epoch: 5 - Loss: 0.014865\n",
      "Epoch: 5 - Loss: 0.141632\n",
      "Epoch: 5 - Loss: 0.099468\n",
      "Epoch: 5 - Loss: 0.003093\n",
      "Epoch: 5 - Loss: 0.009699\n",
      "Epoch: 5 - Loss: 0.160624\n",
      "Epoch: 5 - Loss: 0.027649\n",
      "Epoch: 5 - Loss: 0.210503\n",
      "Epoch: 5 - Loss: 0.007796\n",
      "Epoch: 5 - Loss: 0.141456\n",
      "Epoch: 5 - Loss: 0.055208\n",
      "Epoch: 5 - valid Loss: 0.118766 - valid_acc : 0.963273\n",
      "Epoch: 6 - Loss: 0.001807\n",
      "Epoch: 6 - Loss: 0.017511\n",
      "Epoch: 6 - Loss: 0.022084\n",
      "Epoch: 6 - Loss: 0.038176\n",
      "Epoch: 6 - Loss: 0.141462\n",
      "Epoch: 6 - Loss: 0.221284\n",
      "Epoch: 6 - Loss: 0.185052\n",
      "Epoch: 6 - Loss: 0.032400\n",
      "Epoch: 6 - Loss: 0.247673\n",
      "Epoch: 6 - Loss: 0.044321\n",
      "Epoch: 6 - Loss: 0.163679\n",
      "Epoch: 6 - Loss: 0.235262\n",
      "Epoch: 6 - Loss: 0.041427\n",
      "Epoch: 6 - Loss: 0.022151\n",
      "Epoch: 6 - Loss: 0.011224\n",
      "Epoch: 6 - Loss: 0.252299\n",
      "Epoch: 6 - Loss: 0.004491\n",
      "Epoch: 6 - Loss: 0.169589\n",
      "Epoch: 6 - valid Loss: 0.100414 - valid_acc : 0.968592\n",
      "Epoch: 7 - Loss: 0.121741\n",
      "Epoch: 7 - Loss: 0.151281\n",
      "Epoch: 7 - Loss: 0.103216\n",
      "Epoch: 7 - Loss: 0.072379\n",
      "Epoch: 7 - Loss: 0.000454\n",
      "Epoch: 7 - Loss: 0.018987\n",
      "Epoch: 7 - Loss: 0.167395\n",
      "Epoch: 7 - Loss: 0.146128\n",
      "Epoch: 7 - Loss: 0.005060\n",
      "Epoch: 7 - Loss: 0.443648\n",
      "Epoch: 7 - Loss: 0.038381\n",
      "Epoch: 7 - Loss: 0.006571\n",
      "Epoch: 7 - Loss: 0.279486\n",
      "Epoch: 7 - Loss: 0.015717\n",
      "Epoch: 7 - Loss: 0.000488\n",
      "Epoch: 7 - Loss: 0.021911\n",
      "Epoch: 7 - Loss: 0.032429\n",
      "Epoch: 7 - Loss: 0.000493\n",
      "Epoch: 7 - valid Loss: 0.084092 - valid_acc : 0.975684\n",
      "Epoch: 8 - Loss: 0.224663\n",
      "Epoch: 8 - Loss: 0.004551\n",
      "Epoch: 8 - Loss: 0.000180\n",
      "Epoch: 8 - Loss: 0.000019\n",
      "Epoch: 8 - Loss: 0.004553\n",
      "Epoch: 8 - Loss: 0.053402\n",
      "Epoch: 8 - Loss: 0.046045\n",
      "Epoch: 8 - Loss: 0.022952\n",
      "Epoch: 8 - Loss: 0.089702\n",
      "Epoch: 8 - Loss: 0.018648\n",
      "Epoch: 8 - Loss: 0.010856\n",
      "Epoch: 8 - Loss: 0.002023\n",
      "Epoch: 8 - Loss: 0.000438\n",
      "Epoch: 8 - Loss: 0.114663\n",
      "Epoch: 8 - Loss: 0.032316\n",
      "Epoch: 8 - Loss: 0.078268\n",
      "Epoch: 8 - Loss: 0.057586\n",
      "Epoch: 8 - Loss: 0.004170\n",
      "Epoch: 8 - valid Loss: 0.100956 - valid_acc : 0.966819\n",
      "Epoch: 9 - Loss: 0.262765\n",
      "Epoch: 9 - Loss: 0.000138\n",
      "Epoch: 9 - Loss: 0.006770\n",
      "Epoch: 9 - Loss: 0.119671\n",
      "Epoch: 9 - Loss: 0.033057\n",
      "Epoch: 9 - Loss: 0.038284\n",
      "Epoch: 9 - Loss: 0.048100\n",
      "Epoch: 9 - Loss: 0.003661\n",
      "Epoch: 9 - Loss: 0.029396\n",
      "Epoch: 9 - Loss: 0.014124\n",
      "Epoch: 9 - Loss: 0.086110\n",
      "Epoch: 9 - Loss: 0.012825\n",
      "Epoch: 9 - Loss: 0.022129\n",
      "Epoch: 9 - Loss: 0.000373\n",
      "Epoch: 9 - Loss: 0.000012\n",
      "Epoch: 9 - Loss: 0.210219\n",
      "Epoch: 9 - Loss: 0.027054\n",
      "Epoch: 9 - Loss: 0.031495\n",
      "Epoch: 9 - valid Loss: 0.108126 - valid_acc : 0.968592\n",
      "=============== 4 fold start===============\n",
      "Epoch: 0 - Loss: 2.694043\n",
      "Epoch: 0 - Loss: 1.075563\n",
      "Epoch: 0 - Loss: 0.608841\n",
      "Epoch: 0 - Loss: 0.644554\n",
      "Epoch: 0 - Loss: 0.384249\n",
      "Epoch: 0 - Loss: 0.479461\n",
      "Epoch: 0 - Loss: 0.387246\n",
      "Epoch: 0 - Loss: 0.302484\n",
      "Epoch: 0 - Loss: 0.633358\n",
      "Epoch: 0 - Loss: 0.665294\n",
      "Epoch: 0 - Loss: 0.305837\n",
      "Epoch: 0 - Loss: 0.648149\n",
      "Epoch: 0 - Loss: 0.249277\n",
      "Epoch: 0 - Loss: 0.790439\n",
      "Epoch: 0 - Loss: 0.306433\n",
      "Epoch: 0 - Loss: 0.318213\n",
      "Epoch: 0 - Loss: 0.363004\n",
      "Epoch: 0 - Loss: 0.331498\n",
      "Epoch: 0 - valid Loss: 0.565841 - valid_acc : 0.779889\n",
      "Epoch: 1 - Loss: 0.775188\n",
      "Epoch: 1 - Loss: 0.303921\n",
      "Epoch: 1 - Loss: 0.058783\n",
      "Epoch: 1 - Loss: 0.460059\n",
      "Epoch: 1 - Loss: 0.543133\n",
      "Epoch: 1 - Loss: 0.448509\n",
      "Epoch: 1 - Loss: 0.183627\n",
      "Epoch: 1 - Loss: 0.203718\n",
      "Epoch: 1 - Loss: 0.034211\n",
      "Epoch: 1 - Loss: 0.289310\n",
      "Epoch: 1 - Loss: 0.249118\n",
      "Epoch: 1 - Loss: 0.546392\n",
      "Epoch: 1 - Loss: 0.198324\n",
      "Epoch: 1 - Loss: 0.242387\n",
      "Epoch: 1 - Loss: 0.009916\n",
      "Epoch: 1 - Loss: 0.126895\n",
      "Epoch: 1 - Loss: 0.064830\n",
      "Epoch: 1 - Loss: 0.016040\n",
      "Epoch: 1 - valid Loss: 0.296175 - valid_acc : 0.929585\n",
      "Epoch: 2 - Loss: 0.058077\n",
      "Epoch: 2 - Loss: 0.020446\n",
      "Epoch: 2 - Loss: 0.147113\n",
      "Epoch: 2 - Loss: 0.221693\n",
      "Epoch: 2 - Loss: 0.002617\n",
      "Epoch: 2 - Loss: 0.125576\n",
      "Epoch: 2 - Loss: 0.026043\n",
      "Epoch: 2 - Loss: 0.053028\n",
      "Epoch: 2 - Loss: 0.309154\n",
      "Epoch: 2 - Loss: 0.042338\n",
      "Epoch: 2 - Loss: 0.011598\n",
      "Epoch: 2 - Loss: 0.116249\n",
      "Epoch: 2 - Loss: 0.437335\n",
      "Epoch: 2 - Loss: 0.025411\n",
      "Epoch: 2 - Loss: 1.312928\n",
      "Epoch: 2 - Loss: 0.089309\n",
      "Epoch: 2 - Loss: 0.083887\n",
      "Epoch: 2 - Loss: 0.015074\n",
      "Epoch: 2 - valid Loss: 0.136626 - valid_acc : 0.956180\n",
      "Epoch: 3 - Loss: 0.542596\n",
      "Epoch: 3 - Loss: 0.016724\n",
      "Epoch: 3 - Loss: 0.069233\n",
      "Epoch: 3 - Loss: 0.013200\n",
      "Epoch: 3 - Loss: 0.068279\n",
      "Epoch: 3 - Loss: 0.011582\n",
      "Epoch: 3 - Loss: 0.045643\n",
      "Epoch: 3 - Loss: 0.039666\n",
      "Epoch: 3 - Loss: 0.061507\n",
      "Epoch: 3 - Loss: 0.476790\n",
      "Epoch: 3 - Loss: 0.055831\n",
      "Epoch: 3 - Loss: 0.006801\n",
      "Epoch: 3 - Loss: 0.027871\n",
      "Epoch: 3 - Loss: 0.267897\n",
      "Epoch: 3 - Loss: 0.065664\n",
      "Epoch: 3 - Loss: 0.149958\n",
      "Epoch: 3 - Loss: 0.233774\n",
      "Epoch: 3 - Loss: 0.245263\n",
      "Epoch: 3 - valid Loss: 0.124026 - valid_acc : 0.950861\n",
      "Epoch: 4 - Loss: 0.210769\n",
      "Epoch: 4 - Loss: 0.013490\n",
      "Epoch: 4 - Loss: 0.065725\n",
      "Epoch: 4 - Loss: 0.007114\n",
      "Epoch: 4 - Loss: 0.021018\n",
      "Epoch: 4 - Loss: 0.013741\n",
      "Epoch: 4 - Loss: 0.061224\n",
      "Epoch: 4 - Loss: 0.330138\n",
      "Epoch: 4 - Loss: 0.010566\n",
      "Epoch: 4 - Loss: 0.097237\n",
      "Epoch: 4 - Loss: 0.003021\n",
      "Epoch: 4 - Loss: 0.020378\n",
      "Epoch: 4 - Loss: 0.335285\n",
      "Epoch: 4 - Loss: 0.011427\n",
      "Epoch: 4 - Loss: 0.107200\n",
      "Epoch: 4 - Loss: 0.065429\n",
      "Epoch: 4 - Loss: 0.008489\n",
      "Epoch: 4 - Loss: 0.100929\n",
      "Epoch: 4 - valid Loss: 0.153410 - valid_acc : 0.956180\n",
      "Epoch: 5 - Loss: 0.065038\n",
      "Epoch: 5 - Loss: 0.014758\n",
      "Epoch: 5 - Loss: 0.068512\n",
      "Epoch: 5 - Loss: 0.183249\n",
      "Epoch: 5 - Loss: 0.007531\n",
      "Epoch: 5 - Loss: 0.030729\n",
      "Epoch: 5 - Loss: 0.308313\n",
      "Epoch: 5 - Loss: 0.052323\n",
      "Epoch: 5 - Loss: 0.038730\n",
      "Epoch: 5 - Loss: 0.092889\n",
      "Epoch: 5 - Loss: 0.005042\n",
      "Epoch: 5 - Loss: 0.127370\n",
      "Epoch: 5 - Loss: 0.549437\n",
      "Epoch: 5 - Loss: 0.048387\n",
      "Epoch: 5 - Loss: 0.094182\n",
      "Epoch: 5 - Loss: 0.130164\n",
      "Epoch: 5 - Loss: 0.297896\n",
      "Epoch: 5 - Loss: 0.121023\n",
      "Epoch: 5 - valid Loss: 0.088394 - valid_acc : 0.956181\n",
      "Epoch: 6 - Loss: 0.001293\n",
      "Epoch: 6 - Loss: 0.155370\n",
      "Epoch: 6 - Loss: 0.074459\n",
      "Epoch: 6 - Loss: 0.039262\n",
      "Epoch: 6 - Loss: 0.010719\n",
      "Epoch: 6 - Loss: 0.085473\n",
      "Epoch: 6 - Loss: 0.202634\n",
      "Epoch: 6 - Loss: 0.025286\n",
      "Epoch: 6 - Loss: 0.006761\n",
      "Epoch: 6 - Loss: 0.872904\n",
      "Epoch: 6 - Loss: 0.001822\n",
      "Epoch: 6 - Loss: 0.138629\n",
      "Epoch: 6 - Loss: 0.001379\n",
      "Epoch: 6 - Loss: 0.030913\n",
      "Epoch: 6 - Loss: 0.000045\n",
      "Epoch: 6 - Loss: 0.137948\n",
      "Epoch: 6 - Loss: 0.073034\n",
      "Epoch: 6 - Loss: 0.085189\n",
      "Epoch: 6 - valid Loss: 0.109867 - valid_acc : 0.968592\n",
      "Epoch: 7 - Loss: 0.017434\n",
      "Epoch: 7 - Loss: 0.036379\n",
      "Epoch: 7 - Loss: 0.010465\n",
      "Epoch: 7 - Loss: 0.002413\n",
      "Epoch: 7 - Loss: 0.004055\n",
      "Epoch: 7 - Loss: 0.036205\n",
      "Epoch: 7 - Loss: 0.262927\n",
      "Epoch: 7 - Loss: 0.001720\n",
      "Epoch: 7 - Loss: 0.524867\n",
      "Epoch: 7 - Loss: 0.001763\n",
      "Epoch: 7 - Loss: 0.026607\n",
      "Epoch: 7 - Loss: 0.001015\n",
      "Epoch: 7 - Loss: 0.000341\n",
      "Epoch: 7 - Loss: 0.072848\n",
      "Epoch: 7 - Loss: 0.021617\n",
      "Epoch: 7 - Loss: 0.017035\n",
      "Epoch: 7 - Loss: 0.145982\n",
      "Epoch: 7 - Loss: 0.001247\n",
      "Epoch: 7 - valid Loss: 0.095609 - valid_acc : 0.972138\n",
      "Epoch: 8 - Loss: 0.134119\n",
      "Epoch: 8 - Loss: 0.072409\n",
      "Epoch: 8 - Loss: 0.168507\n",
      "Epoch: 8 - Loss: 0.105156\n",
      "Epoch: 8 - Loss: 0.300186\n",
      "Epoch: 8 - Loss: 0.111152\n",
      "Epoch: 8 - Loss: 0.067733\n",
      "Epoch: 8 - Loss: 0.000783\n",
      "Epoch: 8 - Loss: 0.006212\n",
      "Epoch: 8 - Loss: 0.303419\n",
      "Epoch: 8 - Loss: 0.102280\n",
      "Epoch: 8 - Loss: 0.101740\n",
      "Epoch: 8 - Loss: 0.028126\n",
      "Epoch: 8 - Loss: 0.000683\n",
      "Epoch: 8 - Loss: 0.425999\n",
      "Epoch: 8 - Loss: 0.021252\n",
      "Epoch: 8 - Loss: 0.352726\n",
      "Epoch: 8 - Loss: 0.010196\n",
      "Epoch: 8 - valid Loss: 0.075986 - valid_acc : 0.979230\n",
      "Epoch: 9 - Loss: 0.021225\n",
      "Epoch: 9 - Loss: 0.000085\n",
      "Epoch: 9 - Loss: 0.036818\n",
      "Epoch: 9 - Loss: 0.000123\n",
      "Epoch: 9 - Loss: 0.002268\n",
      "Epoch: 9 - Loss: 0.010889\n",
      "Epoch: 9 - Loss: 0.347424\n",
      "Epoch: 9 - Loss: 0.110758\n",
      "Epoch: 9 - Loss: 0.812825\n",
      "Epoch: 9 - Loss: 0.006823\n",
      "Epoch: 9 - Loss: 0.000214\n",
      "Epoch: 9 - Loss: 0.000033\n",
      "Epoch: 9 - Loss: 0.010472\n",
      "Epoch: 9 - Loss: 0.000042\n",
      "Epoch: 9 - Loss: 0.562722\n",
      "Epoch: 9 - Loss: 0.014483\n",
      "Epoch: 9 - Loss: 0.001458\n",
      "Epoch: 9 - Loss: 0.015837\n",
      "Epoch: 9 - valid Loss: 0.160490 - valid_acc : 0.957954\n"
     ]
    }
   ],
   "source": [
    "num_epochs = CFG['EPOCHS'] \n",
    "best_models = [] # 폴드별로 가장 validation acc가 높은 모델 저장\n",
    "\n",
    "for i,fold in enumerate(range(4)):\n",
    "    print('===============',i+1,'fold start===============')\n",
    "\n",
    "    model = Model()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=CFG['LEARNING_RATE'] )\n",
    "    criterion = nn.CrossEntropyLoss() \n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                                   step_size = 5,\n",
    "                                                   gamma = 0.9) # learning rate scheduler 로 학습률 주기적 감소\n",
    "\n",
    "    train_idx = folds[fold][0] \n",
    "    val_idx = folds[fold][1]\n",
    "\n",
    "\n",
    "    train_dataset = CustomDataset(train_img_path, train_label, train_mode=True, transforms=train_transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n",
    "\n",
    "    val_dataset = CustomDataset(val_img_path, val_label, train_mode=True, transforms=test_transform)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "    val_acc_max = 0.85\n",
    "    val_loss_min = 0.3\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        #모델 학습\n",
    "        for i, (images, targets) in enumerate(train_loader):\n",
    "            model.train()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if (i+1) % 20 == 0:\n",
    "                print(f'Epoch: {epoch} - Loss: {loss:.6f}')\n",
    "\n",
    "\n",
    "        val_loss_list = []\n",
    "        val_acc_list = []\n",
    "        # 모델 검증\n",
    "        for i, (images, targets) in enumerate(val_loader):\n",
    "            model.eval()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(images)\n",
    "                val_loss = criterion(outputs,targets)\n",
    "\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "            \n",
    "                batch_acc = (preds==targets).float().mean() # boolean 값의 평균\n",
    "\n",
    "                val_loss_list.append(val_loss)\n",
    "                val_acc_list.append(batch_acc)\n",
    "\n",
    "        val_loss = np.mean(val_loss_list)\n",
    "        val_acc = np.mean(val_acc_list)\n",
    "\n",
    "        print(f'Epoch: {epoch} - valid Loss: {val_loss:.6f} - valid_acc : {val_acc:.6f}')\n",
    "\n",
    "        # 정확도 기준 성능 좋은 모델 / 혹은 loss 기준 가능\n",
    "        '''\n",
    "         if valid_acc_max < val_acc:\n",
    "            valid_acc_max = val_acc\n",
    "            best_models.append(model)\n",
    "            print('model save, model val acc : ',val_acc)\n",
    "            print('best_models size : ',len(best_models))\n",
    "            '''\n",
    "\n",
    "\n",
    "        if val_loss_min > val_loss:\n",
    "            val_loss_min = val_loss\n",
    "            best_models.append(model)\n",
    "\n",
    "    # lr 조절\n",
    "    lr_scheduler.step()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-28T15:50:37.537861300Z",
     "start_time": "2023-10-28T10:38:27.967971600Z"
    }
   },
   "id": "cb51b81e12055963"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "폴드 1용 모델이 ../saved_models\\model_fold_1.pth에 저장\n",
      "폴드 2용 모델이 ../saved_models\\model_fold_2.pth에 저장\n",
      "폴드 3용 모델이 ../saved_models\\model_fold_3.pth에 저장\n",
      "폴드 4용 모델이 ../saved_models\\model_fold_4.pth에 저장\n",
      "폴드 5용 모델이 ../saved_models\\model_fold_5.pth에 저장\n",
      "폴드 6용 모델이 ../saved_models\\model_fold_6.pth에 저장\n",
      "폴드 7용 모델이 ../saved_models\\model_fold_7.pth에 저장\n",
      "폴드 8용 모델이 ../saved_models\\model_fold_8.pth에 저장\n",
      "폴드 9용 모델이 ../saved_models\\model_fold_9.pth에 저장\n",
      "폴드 10용 모델이 ../saved_models\\model_fold_10.pth에 저장\n",
      "폴드 11용 모델이 ../saved_models\\model_fold_11.pth에 저장\n",
      "폴드 12용 모델이 ../saved_models\\model_fold_12.pth에 저장\n",
      "폴드 13용 모델이 ../saved_models\\model_fold_13.pth에 저장\n",
      "폴드 14용 모델이 ../saved_models\\model_fold_14.pth에 저장\n",
      "폴드 15용 모델이 ../saved_models\\model_fold_15.pth에 저장\n",
      "폴드 16용 모델이 ../saved_models\\model_fold_16.pth에 저장\n",
      "폴드 17용 모델이 ../saved_models\\model_fold_17.pth에 저장\n",
      "폴드 18용 모델이 ../saved_models\\model_fold_18.pth에 저장\n",
      "폴드 19용 모델이 ../saved_models\\model_fold_19.pth에 저장\n",
      "폴드 20용 모델이 ../saved_models\\model_fold_20.pth에 저장\n",
      "폴드 21용 모델이 ../saved_models\\model_fold_21.pth에 저장\n",
      "폴드 22용 모델이 ../saved_models\\model_fold_22.pth에 저장\n"
     ]
    }
   ],
   "source": [
    "# 모델 선택: 여기서는 best_models 리스트의 첫 번째 모델을 사용합니다.\n",
    "model = best_models[0]\n",
    "\n",
    "# 추론할 이미지 선택: 여기서는 첫 번째 테스트 이미지를 선택합니다.\n",
    "image_index = 0  # 추론할 이미지의 인덱스\n",
    "image, true_label = test_dataset[image_index]\n",
    "\n",
    "# 모델 추론\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(image.unsqueeze(0))  # 배치 차원 추가\n",
    "    predicted_label = torch.argmax(output, dim=1).item()\n",
    "\n",
    "# 클래스 레이블 가져오기 (예: 클래스 레이블이 문자열인 경우)\n",
    "class_labels = ['class_0', 'class_1', 'class_2', ...]  # 클래스 레이블 리스트\n",
    "predicted_class = class_labels[predicted_label]\n",
    "true_class = class_labels[true_label.item()]\n",
    "\n",
    "# 이미지와 추론 결과를 시각화\n",
    "plt.figure()\n",
    "plt.title(f'True Label: {true_class}, Predicted Label: {predicted_class}')\n",
    "image = image.permute(1, 2, 0)  # 이미지 차원 순서 변경\n",
    "plt.imshow(image)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-28T16:31:55.576736300Z",
     "start_time": "2023-10-28T16:31:53.835729Z"
    }
   },
   "id": "5be8673df2543b66"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "test_dataset = CustomDataset(test_img_path, test_label, train_mode=False, transforms=None) \n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "\n",
    "preds = []\n",
    "for idx,model in enumerate(best_models[:1]):\n",
    "    print(idx+1, '번째 모델 예측 진행중')\n",
    "    model = model\n",
    "    model.eval()\n",
    "    y_pred = []\n",
    "    with torch.no_grad():\n",
    "        for i, d in enumerate(test_loader):\n",
    "            inputs = d.to('cuda')\n",
    "            outputs = model(inputs).detach().cpu().numpy()\n",
    "            y_pred.extend(outputs.argmax(axis=1).astype(int))\n",
    "\n",
    "    preds.append(y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-10-28T15:52:54.332578700Z"
    }
   },
   "id": "9eb8addab7842bd7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model_folder = 'E:\\\\2023\\\\2023_1_1\\comp\\saved_models'\n",
    "model_template = 'model_fold_{}.pth'\n",
    "\n",
    "test_dataset = CustomDataset(test_img_path, test_label, train_mode=False, transforms=None)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "\n",
    "preds = []\n",
    "for model in range(1, 23):\n",
    "    model_path = os.path.join(model_folder, model_template.format(model))\n",
    "    if os.path.exists(model_path):\n",
    "        print(f'Loading model {model}')\n",
    "\n",
    "        model = torch.load(model_path)\n",
    "        model.eval()\n",
    "\n",
    "        y_pred = []\n",
    "        with torch.no_grad():\n",
    "            for i, d in enumerate(test_loader):\n",
    "                inputs = d\n",
    "                outputs = model(inputs).detach().cpu().numpy()\n",
    "                y_pred.extend(outputs.argmax(axis=1).astype(int))\n",
    "        preds.append(y_pred)\n",
    "    else:\n",
    "        print(f'Model {model} not found.')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "64aa5045894a5f4d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
